{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from osgeo import gdal\n",
    "from sentinelhub import AwsProductRequest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_credential(id_name):\n",
    "    file_path = os.getcwd() + '/credentials.sh'\n",
    "    f = open(file_path, 'r+')\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        ids = line.strip().split('=')\n",
    "        if ids[0] == id_name:\n",
    "            return ids[1].strip()\n",
    "    return 'Not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME = [get_credential(\"username\"), get_credential(\"username1\")]\n",
    "PASSWORD = [get_credential(\"password\"), get_credential(\"password1\")]\n",
    "API_SOURCE = \"https://scihub.copernicus.eu/dhus\"\n",
    "PROCESSING_LEVEL = [\"Level-1\", \"Level-2\"]\n",
    "SATELLITE = \"Sentinel-2\"\n",
    "STUDY_AREA = \"GodavariNew.geojson\"\n",
    "REGION = \"Godavari\"\n",
    "CWD = \"\"+os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEB_2016 = \"20160209\"\n",
    "FEB_END16 = \"20160308\"\n",
    "\n",
    "FEB_2017 = \"20170209\"\n",
    "FEB_END17 = \"20170308\"\n",
    "\n",
    "FEB_2018 = \"20180209\"\n",
    "FEB_END18 = \"20180308\"\n",
    "\n",
    "FEB_2019 = \"20190209\"\n",
    "FEB_END19 = \"20190308\"\n",
    "\n",
    "FEB_2020 = \"20200120\"\n",
    "FEB_END20 = \"20200318\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [\n",
    "    \"Feb16\", \"Feb17\", \"Feb18\", \"Feb19\", \"Feb20\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates = [[FEB_2019, FEB_END19], [FEB_2020, FEB_END20]]\n",
    "dates = [[FEB_2016, FEB_END16], [FEB_2017, FEB_END17], [FEB_2018, FEB_END18], [FEB_2019, FEB_END19], [FEB_2020, FEB_END20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "footprint = geojson_to_wkt(read_geojson(STUDY_AREA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = []\n",
    "for i in range(len(USERNAME)):\n",
    "    api.append(SentinelAPI(USERNAME[i], PASSWORD[i], API_SOURCE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryForProducts(footprint, beg, end, sat):\n",
    "    return api[0].query(footprint, date=(beg, end),platformname=sat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLevelURLs(df):\n",
    "    level1 = []\n",
    "    for i in range(df.shape[0]):\n",
    "        if PROCESSING_LEVEL[0] in df[\"processinglevel\"][i]:\n",
    "            level1.append(df[\"link\"][i])\n",
    "\n",
    "    level2 = []\n",
    "    for i in range(df.shape[0]):\n",
    "        if PROCESSING_LEVEL[1] in df[\"processinglevel\"][i]:\n",
    "            level2.append(df[\"link\"][i])\n",
    "    \n",
    "    return level1, level2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curateLevelProducts(products, df, level):\n",
    "    keys = list(products.keys())\n",
    "    for i in range(df.shape[0]):\n",
    "        if level not in df[\"processinglevel\"][i]:\n",
    "            products.pop(keys[i])\n",
    "    return products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataDirectory(name):\n",
    "    data_dir = os.getcwd()+\"\\\\data\\\\\"+name+\"_data\"\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.mkdir(data_dir)\n",
    "    return data_dir\n",
    "def getDataDirectory(name):\n",
    "    return os.getcwd()+\"\\\\data\\\\\"+name+\"_data\"\n",
    "def createArchiveDirectory(name):\n",
    "    data_dir = os.getcwd()+\"\\\\data\\\\\"+name+\"_archive\"\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.mkdir(data_dir)\n",
    "    return data_dir\n",
    "def getArchiveDirectory(name):\n",
    "    return os.getcwd()+\"\\\\data\\\\\"+name+\"_archive\"\n",
    "def createBackupDirectory(name):\n",
    "    backup = \"D:\\\\\"+name+\"_data\"\n",
    "    if not os.path.exists(backup):\n",
    "        os.mkdir(backup)\n",
    "    return backup\n",
    "def getBackupDirectory(name):\n",
    "    return \"D:\\\\\"+name+\"_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listDataFiles(data_dir, ext):\n",
    "    paths = glob(data_dir+\"/*\"+ext)\n",
    "    fileNames = []\n",
    "    for path in paths:\n",
    "        fileNames.append(path.split('.')[0].split('\\\\')[-1])\n",
    "    return paths, fileNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDesiredFiles(data_det):\n",
    "    product_ids = (list(data_det.keys()))\n",
    "    desired_files = []\n",
    "    for pid in product_ids:\n",
    "        desired_files.append(data_det[pid]['title'])\n",
    "    return desired_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAllFiles(data_det):\n",
    "    desired_files = getDesiredFiles(data_det)\n",
    "    for file_name in desired_files:\n",
    "        date = file_name.split('_')[2][:6]\n",
    "        file_path = getDataDirectory(REGION+str(date))+\"\\\\\"+file_name+\".SAFE\"\n",
    "        if not os.path.exists(file_path):\n",
    "            print(file_path)\n",
    "    print(\"All other files downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFiles(data_dir):\n",
    "    paths, fileNames = listDataFiles(data_dir, \".zip\")\n",
    "    l = len(paths)\n",
    "    i = 0\n",
    "    for path in paths:\n",
    "        print(str(i)+\"/\"+str(l)+\"  Extracting \"+path.split('.')[0].split('\\\\')[-1]+\"...\")\n",
    "        with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOnlineProducts(data_det):\n",
    "    online_products = []\n",
    "    for products in data_det:\n",
    "        for prod in products:\n",
    "            if api[0].get_product_odata(prod)['Online']:\n",
    "                online_products.append(products[prod]['title'])\n",
    "    return online_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(data_dir):\n",
    "    paths, fileNames = listDataFiles(data_dir, \".zip\")\n",
    "    l = len(paths)\n",
    "    i = 0\n",
    "    for path in paths:\n",
    "        print(str(i)+\"/\"+str(l)+\"Deleting \"+path.split('.')[0].split('\\\\')[-1]+\"...\")\n",
    "        os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFolders(data_dir):\n",
    "    #return all  data folders  list\n",
    "    return\n",
    "def manipualateFolders(data_dir):\n",
    "    #extract  annd cleannn for  all get folders\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getData(products):\n",
    "    CWD = Path(os.getcwd())\n",
    "    try:\n",
    "        date = products[list(products.keys())[0]]['title'].split('_')[2][:4]\n",
    "        path = createDataDirectory(REGION+str(date))\n",
    "        if not api[0].get_product_odata(prod)['Online']:\n",
    "            path = createArchiveDirectory(REGION+str(date))\n",
    "        print(\"Changing Directory \" + path)\n",
    "        os.chdir(path)\n",
    "        for prod in products:\n",
    "            if api[0].get_product_odata(prod)['Online'] and (not os.path.exists(path+'\\\\'+products[prod]['title']+'.zip')):\n",
    "                print(prod+\"----\"+products[prod]['title'])\n",
    "                api[0].download(prod)\n",
    "            elif os.path.exists(path+'\\\\'+products[prod]['title']+'.zip'):\n",
    "                print(products[prod]['title'])\n",
    "            else:\n",
    "                #print(products[prod]['title'])\n",
    "                print(prod+\" not online. Downloading using AWS EC2 instance :)\")\n",
    "                #product_request = AwsProductRequest(product_id=products[prod]['title'],\n",
    "                                    #data_folder=path, safe_format=True)\n",
    "                #product_request.get_data(save_data=True)                \n",
    "        #path=path+file_name\n",
    "        #backupPath = createBackupDirectory(REGION+str(date))\n",
    "        #print(\"Backup \" + file_name + \" to \" + backupPath)\n",
    "        #shutil.copy2(path,backupPath)\n",
    "        #extractFile(path)\n",
    "        #cleanup(path)\n",
    "        os.chdir(CWD)\n",
    "    except AssertionError:\n",
    "        os.chdir(CWD)\n",
    "        print(os.getcwd())\n",
    "        print(\"Download of specified products done\")\n",
    "    except Exception as e:\n",
    "        os.chdir(CWD)\n",
    "        print(os.getcwd())\n",
    "        print(\"Something went wrong \" + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = []\n",
    "for date in dates:\n",
    "    products.append(queryForProducts(footprint, date[0], date[1],SATELLITE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df  =  []\n",
    "level1 = []\n",
    "level2 = []\n",
    "for product in products:\n",
    "    products_df.append(api[0].to_dataframe(product))\n",
    "    l1, l2 = getLevelURLs(products_df[-1])\n",
    "    level1.append(l1)\n",
    "    level2.append(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "6\n",
      "18\n",
      "19\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "data_det = []\n",
    "for i in range(len(products_df)):\n",
    "    temp = copy.deepcopy(products[i])\n",
    "    det_l2 = curateLevelProducts(products[i], products_df[i], PROCESSING_LEVEL[1])\n",
    "    det_l1 = curateLevelProducts(temp, products_df[i], PROCESSING_LEVEL[0])\n",
    "    if len(det_l2) >= len(det_l1):\n",
    "        data_det.append(det_l2)\n",
    "    else:\n",
    "        data_det.append(det_l1)\n",
    "    print(len(data_det[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Total  L1  L2\n",
      "Feb16   2     2  0\n",
      "Feb17   6     6  0\n",
      "Feb18   18     18  0\n",
      "Feb19   38     19  19\n",
      "Feb20   76     38  38\n"
     ]
    }
   ],
   "source": [
    "levelCount = []\n",
    "\n",
    "for i in range(len(products_df)):\n",
    "    counts = [products_df[i].shape[0], len(level1[i]), len(level2[i])]\n",
    "    levelCount.append(counts)\n",
    "\n",
    "print(\"      Total  L1  L2\")\n",
    "for i in range(len(levelCount)):\n",
    "    print(months[i] + \"   \" + str(levelCount[i][0]) + \"     \" + str(levelCount[i][1]) + \"  \" + str(levelCount[i][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing Directory C:\\Users\\Hello\\Documents\\remote-sensing\\APIs\\SentinelSat\\data\\Godavari2016_data\n",
      "S2A_MSIL1C_20160213T044912_N0201_R076_T44QPD_20160213T050114\n",
      "S2A_MSIL1C_20160213T044912_N0201_R076_T44QPE_20160213T050114\n",
      "Changing Directory C:\\Users\\Hello\\Documents\\remote-sensing\\APIs\\SentinelSat\\data\\Godavari2017_data\n",
      "S2A_MSIL1C_20170302T045711_N0204_R119_T44QPE_20170302T050237\n",
      "S2A_MSIL1C_20170302T045711_N0204_R119_T44QPD_20170302T050237\n",
      "S2A_MSIL1C_20170302T045711_N0204_R119_T44QND_20170302T050237\n",
      "S2A_MSIL1C_20170210T045931_N0204_R119_T44QND_20170210T050445\n",
      "S2A_MSIL1C_20170210T045931_N0204_R119_T44QPE_20170210T050445\n",
      "S2A_MSIL1C_20170210T045931_N0204_R119_T44QPD_20170210T050445\n",
      "Changing Directory C:\\Users\\Hello\\Documents\\remote-sensing\\APIs\\SentinelSat\\data\\Godavari2018_data\n",
      "S2A_MSIL1C_20180307T045651_N0206_R119_T44QND_20180307T075359\n",
      "S2A_MSIL1C_20180307T045651_N0206_R119_T44QPE_20180307T075359\n",
      "S2A_MSIL1C_20180307T045651_N0206_R119_T44QPD_20180307T075359\n",
      "S2B_MSIL1C_20180302T045709_N0206_R119_T44QND_20180302T074504\n",
      "S2B_MSIL1C_20180302T045709_N0206_R119_T44QPE_20180302T074504\n",
      "S2B_MSIL1C_20180302T045709_N0206_R119_T44QPD_20180302T074504\n",
      "S2A_MSIL1C_20180225T045751_N0206_R119_T44QND_20180225T102148\n",
      "S2A_MSIL1C_20180225T045751_N0206_R119_T44QPD_20180225T102148\n",
      "S2A_MSIL1C_20180225T045751_N0206_R119_T44QPE_20180225T102148\n",
      "S2A_MSIL1C_20180215T045901_N0206_R119_T44QPE_20180215T074952\n",
      "S2A_MSIL1C_20180215T045901_N0206_R119_T44QPD_20180215T074952\n",
      "S2A_MSIL1C_20180215T045901_N0206_R119_T44QND_20180215T074952\n",
      "S2B_MSIL1C_20180220T045829_N0206_R119_T44QPE_20180220T102205\n",
      "S2B_MSIL1C_20180220T045829_N0206_R119_T44QND_20180220T102205\n",
      "S2B_MSIL1C_20180220T045829_N0206_R119_T44QPD_20180220T102205\n",
      "S2B_MSIL1C_20180210T045929_N0206_R119_T44QPD_20180210T060929\n",
      "S2B_MSIL1C_20180210T045929_N0206_R119_T44QND_20180210T060929\n",
      "S2B_MSIL1C_20180210T045929_N0206_R119_T44QPE_20180210T060929\n",
      "Changing Directory C:\\Users\\Hello\\Documents\\remote-sensing\\APIs\\SentinelSat\\data\\Godavari2019_data\n",
      "S2B_MSIL2A_20190307T045659_N0211_R119_T44QPE_20190307T093039\n",
      "S2B_MSIL2A_20190307T045659_N0211_R119_T44QND_20190307T093039\n",
      "S2B_MSIL2A_20190307T045659_N0211_R119_T44QPD_20190307T093039\n",
      "S2A_MSIL2A_20190302T045721_N0211_R119_T44QPD_20190302T092150\n",
      "S2A_MSIL2A_20190302T045721_N0211_R119_T44QPE_20190302T092150\n",
      "S2A_MSIL2A_20190302T045721_N0211_R119_T44QND_20190302T092150\n",
      "S2B_MSIL2A_20190225T045759_N0211_R119_T44QPE_20190225T090218\n",
      "S2B_MSIL2A_20190225T045759_N0211_R119_T44QND_20190225T090218\n",
      "S2B_MSIL2A_20190225T045759_N0211_R119_T44QPD_20190225T090218\n",
      "S2A_MSIL2A_20190220T045831_N0211_R119_T44QND_20190220T084125\n",
      "S2A_MSIL2A_20190220T045831_N0211_R119_T44QPD_20190220T084125\n",
      "S2A_MSIL2A_20190220T045831_N0211_R119_T44QPE_20190220T084125\n",
      "S2B_MSIL2A_20190215T045909_N0211_R119_T44QPE_20190215T084740\n",
      "S2B_MSIL2A_20190215T045909_N0211_R119_T44QPD_20190215T090059\n",
      "S2B_MSIL2A_20190215T045909_N0211_R119_T44QND_20190215T090059\n",
      "S2B_MSIL2A_20190215T045909_N0211_R119_T44QPE_20190215T090059\n",
      "S2A_MSIL2A_20190210T045941_N0211_R119_T44QND_20190210T090457\n",
      "S2A_MSIL2A_20190210T045941_N0211_R119_T44QPE_20190210T090457\n",
      "S2A_MSIL2A_20190210T045941_N0211_R119_T44QPD_20190210T090457\n",
      "Changing Directory C:\\Users\\Hello\\Documents\\remote-sensing\\APIs\\SentinelSat\\data\\Godavari2020_data\n",
      "S2A_MSIL2A_20200316T045651_N0214_R119_T44QPD_20200316T093035\n",
      "S2A_MSIL2A_20200316T045651_N0214_R119_T44QND_20200316T093035\n",
      "S2A_MSIL2A_20200316T045651_N0214_R119_T44QPE_20200316T093035\n",
      "S2B_MSIL2A_20200311T045659_N0214_R119_T44QPD_20200311T110524\n",
      "S2B_MSIL2A_20200311T045659_N0214_R119_T44QND_20200311T110524\n",
      "S2B_MSIL2A_20200311T045659_N0214_R119_T44QPE_20200311T110524\n",
      "S2A_MSIL2A_20200306T045651_N0214_R119_T44QPD_20200306T090503\n",
      "S2A_MSIL2A_20200306T045651_N0214_R119_T44QPE_20200306T090503\n",
      "S2A_MSIL2A_20200306T045651_N0214_R119_T44QND_20200306T090503\n",
      "S2B_MSIL2A_20200301T045719_N0214_R119_T44QND_20200301T092002\n",
      "S2B_MSIL2A_20200301T045719_N0214_R119_T44QPD_20200301T092002\n",
      "S2B_MSIL2A_20200301T045719_N0214_R119_T44QPE_20200301T092002\n",
      "S2A_MSIL2A_20200225T045801_N0214_R119_T44QPE_20200225T090035\n",
      "S2A_MSIL2A_20200225T045801_N0214_R119_T44QND_20200225T090035\n",
      "S2A_MSIL2A_20200225T045801_N0214_R119_T44QPD_20200225T090035\n",
      "S2B_MSIL2A_20200220T045829_N0214_R119_T44QND_20200220T091521\n",
      "S2B_MSIL2A_20200220T045829_N0214_R119_T44QPE_20200220T091521\n",
      "S2B_MSIL2A_20200220T045829_N0214_R119_T44QPD_20200220T091521\n",
      "S2A_MSIL2A_20200215T045901_N0214_R119_T44QND_20200215T091948\n",
      "S2A_MSIL2A_20200215T045901_N0214_R119_T44QPE_20200215T091948\n",
      "S2A_MSIL2A_20200215T045901_N0214_R119_T44QPD_20200215T091948\n",
      "S2B_MSIL2A_20200210T045939_N0214_R119_T44QPD_20200210T092143\n",
      "S2B_MSIL2A_20200210T045939_N0214_R119_T44QND_20200210T092143\n",
      "S2B_MSIL2A_20200210T045939_N0214_R119_T44QPD_20200210T091624\n",
      "S2B_MSIL2A_20200210T045939_N0214_R119_T44QPE_20200210T091624\n",
      "S2B_MSIL2A_20200210T045939_N0214_R119_T44QND_20200210T091624\n",
      "S2A_MSIL2A_20200205T050001_N0214_R119_T44QND_20200206T183220\n",
      "S2A_MSIL2A_20200205T050001_N0214_R119_T44QPE_20200206T183220\n",
      "S2A_MSIL2A_20200205T050001_N0214_R119_T44QPD_20200206T183220\n",
      "S2B_MSIL2A_20200131T050029_N0213_R119_T44QPD_20200131T083759\n",
      "S2B_MSIL2A_20200131T050029_N0213_R119_T44QPE_20200131T083759\n",
      "S2B_MSIL2A_20200131T050029_N0213_R119_T44QND_20200131T083759\n",
      "S2A_MSIL2A_20200126T050051_N0213_R119_T44QPE_20200126T072626\n",
      "S2A_MSIL2A_20200126T050051_N0213_R119_T44QPD_20200126T072626\n",
      "S2A_MSIL2A_20200126T050051_N0213_R119_T44QND_20200126T072626\n",
      "S2B_MSIL2A_20200121T050119_N0213_R119_T44QND_20200121T083544\n",
      "S2B_MSIL2A_20200121T050119_N0213_R119_T44QPD_20200121T083544\n",
      "S2B_MSIL2A_20200121T050119_N0213_R119_T44QPE_20200121T083544\n"
     ]
    }
   ],
   "source": [
    "data_dir = []\n",
    "for i in range(len(data_det)):\n",
    "    getData(data_det[i])\n",
    "    #checkAllFiles(data_det[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
