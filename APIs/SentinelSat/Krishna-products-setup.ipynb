{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from osgeo import gdal\n",
    "from rasterio import rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME = [\"barmasushma1\", \"SumanjaliDamarla\"]\n",
    "PASSWORD = [\"barmasushma1\", \"D.Sumanjali1\"]\n",
    "API_SOURCE = \"https://scihub.copernicus.eu/dhus\"\n",
    "PROCESSING_LEVEL = [\"Level-1\", \"Level-2\"]\n",
    "SATELLITE = \"Sentinel-2\"\n",
    "STUDY_AREA = \"StudyArea.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "footprint = geojson_to_wkt(read_geojson(STUDY_AREA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = []\n",
    "for i in range(len(USERNAME)):\n",
    "    api.append(SentinelAPI(USERNAME[i], PASSWORD[i], API_SOURCE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAYS = {\n",
    "    \"jan\" : '31',\n",
    "    \"feb\" : '28',\n",
    "    \"mar\" : '31',\n",
    "    \"apr\" : '30',\n",
    "    \"may\" : '31',\n",
    "    \"jun\" : '30',\n",
    "    \"jul\" : '31',\n",
    "    \"aug\" : '31',\n",
    "    \"sep\" : '30',\n",
    "    \"oct\" : '31',\n",
    "    \"nov\" : '30',\n",
    "    \"dec\" : '31'\n",
    "}\n",
    "MONTHS = {\n",
    "    \"jan\" : '01',\n",
    "    \"feb\" : '02',\n",
    "    \"mar\" : '03',\n",
    "    \"apr\" : '04',\n",
    "    \"may\" : '05',\n",
    "    \"jun\" : '06',\n",
    "    \"jul\" : '07',\n",
    "    \"aug\" : '08',\n",
    "    \"sep\" : '09',\n",
    "    \"oct\" : '10',\n",
    "    \"nov\" : '11',\n",
    "    \"dec\" : '12'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEC_BEGIN = \"20181201\"\n",
    "DEC_END = \"20181231\"\n",
    "\n",
    "JAN_BEGIN = \"20190101\"\n",
    "JAN_END = \"20190131\"\n",
    "\n",
    "FEB_BEGIN = \"20190201\"\n",
    "FEB_END = \"20190228\"\n",
    "\n",
    "MAR_BEGIN = \"20190301\"\n",
    "MAR_END = \"20190331\"\n",
    "\n",
    "APR_BEGIN = \"20190401\"\n",
    "APR_END = \"20190430\"\n",
    "\n",
    "MAY_BEGIN = \"20190501\"\n",
    "MAY_END = \"20190531\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryForProducts(footprint, beg, end, sat):\n",
    "    return api[0].query(footprint, date=(beg, end),platformname=sat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLevelURLs(df):\n",
    "    level1 = []\n",
    "    for i in range(df.shape[0]):\n",
    "        if PROCESSING_LEVEL[0] in df[\"processinglevel\"][i]:\n",
    "            level1.append(df[\"link\"][i])\n",
    "\n",
    "    level2 = []\n",
    "    for i in range(df.shape[0]):\n",
    "        if PROCESSING_LEVEL[1] in df[\"processinglevel\"][i]:\n",
    "            level2.append(df[\"link\"][i])\n",
    "    \n",
    "    return level1, level2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curateLevelProducts(products, df, level):\n",
    "    keys = list(products.keys())\n",
    "    for i in range(df.shape[0]):\n",
    "        if level not in df[\"processinglevel\"][i]:\n",
    "            products.pop(keys[i])\n",
    "    return products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def downloadDataUsingThread(prod):\n",
    "    try:\n",
    "        t1 = threading.Thread(api[0].download_all(prod))\n",
    "        t1.start()\n",
    "        t1.join()\n",
    "    except AssertionError:\n",
    "        print(\"Download of specified products done\")\n",
    "    except:\n",
    "        print(\"Something went wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataDirectory(month):\n",
    "    data_dir = os.getcwd()+\"\\\\data\\\\\"+month+\"_data\"\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.mkdir(data_dir)\n",
    "    return data_dir\n",
    "def getDataDirectory(month):\n",
    "    return os.getcwd()+\"\\\\data\\\\\"+month+\"_data\"\n",
    "def createBackupDirectory(month):\n",
    "    backup = \"D:\\\\\"+month+\"_data\"\n",
    "    if not os.path.exists(backup):\n",
    "        os.mkdir(backup)\n",
    "    return backup\n",
    "def getBackupDirectory(month):\n",
    "    return \"D:\\\\\"+month+\"_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listDataFiles(data_dir, ext):\n",
    "    paths = glob(data_dir+\"/*\"+ext)\n",
    "    fileNames = []\n",
    "    for path in paths:\n",
    "        fileNames.append(path.split('.')[0].split('\\\\')[-1])\n",
    "    return paths, fileNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAllFiles(data_det, fileNames):\n",
    "    product_ids = (list(data_det.keys()))\n",
    "    desired_files = []\n",
    "    for pid in product_ids:\n",
    "        desired_files.append(data_det[pid]['title'])\n",
    "    return sorted(desired_files) == sorted(fileNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrangeData(month, curr_path, data_det):\n",
    "    curr_paths, FileNames = listDataFiles(curr_path, \".zip\")\n",
    "    if not (checkAllFiles(data_det, FileNames)):\n",
    "        raise Exception(\"All files are not downloaded\")\n",
    "    else:\n",
    "        print(\"All files  Downloaded successfully\")\n",
    "    dst_dir = createDataDirectory(month)\n",
    "    backup = createBackupDirectory(month)\n",
    "    for path in curr_paths:\n",
    "        print(\"Backup files to \"+backup)\n",
    "        shutil.copy2(path, backup)\n",
    "        print(\"Moving files to \"+dst_dir)\n",
    "        shutil.move(path, dst_dir)\n",
    "    return dst_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFiles(data_dir):\n",
    "    paths, fileNames = listDataFiles(data_dir, \".zip\")\n",
    "    l = len(paths)\n",
    "    i = 0\n",
    "    for path in paths:\n",
    "        print(str(i)+\"/\"+str(l)+\"  Extracting \"+path.split('.')[0].split('\\\\')[-1]+\"...\")\n",
    "        with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(data_dir):\n",
    "    paths, fileNames = listDataFiles(data_dir, \".zip\")\n",
    "    l = len(paths)\n",
    "    i = 0\n",
    "    for path in paths:\n",
    "        print(str(i)+\"/\"+str(l)+\"Deleting \"+path.split('.')[0].split('\\\\')[-1]+\"...\")\n",
    "        os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_products = queryForProducts(footprint, DEC_BEGIN, DEC_END,SATELLITE)\n",
    "jan_products = queryForProducts(footprint, JAN_BEGIN, JAN_END,SATELLITE)\n",
    "feb_products = queryForProducts(footprint, FEB_BEGIN, FEB_END,SATELLITE)\n",
    "mar_products = queryForProducts(footprint, MAR_BEGIN, MAR_END,SATELLITE)\n",
    "apr_products = queryForProducts(footprint, APR_BEGIN, APR_END,SATELLITE)\n",
    "may_products = queryForProducts(footprint, MAY_BEGIN, MAY_END,SATELLITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_df = api[0].to_dataframe(dec_products)\n",
    "jan_df = api[0].to_dataframe(jan_products)\n",
    "feb_df = api[0].to_dataframe(feb_products)\n",
    "mar_df = api[0].to_dataframe(mar_products)\n",
    "apr_df = api[0].to_dataframe(apr_products)\n",
    "may_df = api[0].to_dataframe(may_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_level1, dec_level2 = getLevelURLs(dec_df)\n",
    "jan_level1, jan_level2 = getLevelURLs(jan_df)\n",
    "feb_level1, feb_level2 = getLevelURLs(feb_df)\n",
    "mar_level1, mar_level2 = getLevelURLs(mar_df)\n",
    "apr_level1, apr_level2 = getLevelURLs(apr_df)\n",
    "may_level1, may_level2 = getLevelURLs(may_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_data_det = curateLevelProducts(dec_products, dec_df, PROCESSING_LEVEL[1])\n",
    "jan_data_det = curateLevelProducts(jan_products, jan_df, PROCESSING_LEVEL[1])\n",
    "feb_data_det = curateLevelProducts(feb_products, feb_df, PROCESSING_LEVEL[1])\n",
    "mar_data_det = curateLevelProducts(mar_products, mar_df, PROCESSING_LEVEL[1])\n",
    "apr_data_det = curateLevelProducts(apr_products, apr_df, PROCESSING_LEVEL[1])\n",
    "may_data_det = curateLevelProducts(may_products, may_df, PROCESSING_LEVEL[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Total  L1  L2\n",
      "Dec   65     42  23\n",
      "Jan   90     45  45\n",
      "Feb   74     37  37\n",
      "Mar   84     42  42\n",
      "Apr   84     42  42\n",
      "May   84     42  42\n"
     ]
    }
   ],
   "source": [
    "months = [\n",
    "    \"Dec\", \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\"\n",
    "]\n",
    "levelCount = [\n",
    "    [dec_df.shape[0], len(dec_level1), len(dec_level2)],\n",
    "    [jan_df.shape[0], len(jan_level1), len(jan_level2)],\n",
    "    [feb_df.shape[0], len(feb_level1), len(feb_level2)],\n",
    "    [mar_df.shape[0], len(mar_level1), len(mar_level2)],\n",
    "    [apr_df.shape[0], len(apr_level1), len(apr_level2)],\n",
    "    [may_df.shape[0], len(may_level1), len(may_level2)]\n",
    "]\n",
    "\n",
    "print(\"      Total  L1  L2\")\n",
    "for i in range(len(months)):\n",
    "    print(months[i] + \"   \" + str(levelCount[i][0]) + \"     \" + str(levelCount[i][1]) + \"  \" + str(levelCount[i][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadDataUsingThread(dec_data_det)\n",
    "dec_data_dir = arrangeData(\"dec\", os.getcwd(), dec_data_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadDataUsingThread(jan_data_det)\n",
    "jan_data_dir = arrangeData(\"jan\", os.getcwd(), jan_data_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:  30%|███       | 342M/1.13G [50:57<1:57:50, 112kB/s]  \n",
      "MD5 checksumming: 100%|██████████| 342M/342M [00:00<00:00, 531MB/s] \n",
      "Invalid checksum. The downloaded file for '8b3663da-902d-4199-83ec-59a165b20774' is corrupted.\n",
      "Downloading:   9%|▉         | 102M/1.13G [43:41<7:22:34, 38.8kB/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something went wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "All files are not downloaded",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-61c75ebd53f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdownloadDataUsingThread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeb_data_det\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfeb_data_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marrangeData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"feb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeb_data_det\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-f423d2809f74>\u001b[0m in \u001b[0;36marrangeData\u001b[1;34m(month, curr_path, data_det)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mcurr_paths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFileNames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlistDataFiles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\".zip\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcheckAllFiles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_det\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFileNames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All files are not downloaded\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All files  Downloaded successfully\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: All files are not downloaded"
     ]
    }
   ],
   "source": [
    "downloadDataUsingThread(feb_data_det)\n",
    "feb_data_dir = arrangeData(\"feb\", os.getcwd(), feb_data_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadDataUsingThread(mar_data_det)\n",
    "mar_data_dir = arrangeData(\"mar\", os.getcwd(), mar_data_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadDataUsingThread(apr_data_det)\n",
    "apr_data_dir = arrangeData(\"apr\", os.getcwd(), apr_data_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadDataUsingThread(may_data_det)\n",
    "may_data_dir = arrangeData(\"may\", os.getcwd(), may_data_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extractFiles(dec_data_dir)\n",
    "extractFiles(jan_data_dir)\n",
    "extractFiles(feb_data_dir)\n",
    "extractFiles(mar_data_dir)\n",
    "extractFiles(apr_data_dir)\n",
    "extractFiles(may_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_data_dir = getDataDirectory(\"dec\")\n",
    "extractFiles(dec_data_dir)\n",
    "cleanup(dec_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_data_dir = getDataDirectory(\"jan\")\n",
    "extractFiles(jan_data_dir)\n",
    "cleanup(jan_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feb_data_dir = getDataDirectory(\"feb\")\n",
    "extractFiles(feb_data_dir)\n",
    "cleanup(feb_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mar_data_dir = getDataDirectory(\"mar\")\n",
    "extractFiles(mar_data_dir)\n",
    "cleanup(mar_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apr_data_dir = getDataDirectory(\"apr\")\n",
    "extractFiles(apr_data_dir)\n",
    "cleanup(apr_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_data_dir = getDataDirectory(\"may\")\n",
    "extractFiles(may_data_dir)\n",
    "cleanup(may_data_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
